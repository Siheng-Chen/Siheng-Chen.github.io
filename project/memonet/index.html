<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: October 19, 2022 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.7c9112d62aa504adadca15bbc66e8e51.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Siheng Chen"><meta name=description content="**[ CVPR 2022 ]** <br>MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data."><link rel=alternate hreflang=en-us href=https://Siheng-Chen.github.io/project/memonet/><link rel=canonical href=https://Siheng-Chen.github.io/project/memonet/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:image" content="https://Siheng-Chen.github.io/project/memonet/featured.jpg"><meta property="og:site_name" content="Siheng Chen"><meta property="og:url" content="https://Siheng-Chen.github.io/project/memonet/"><meta property="og:title" content="Remember Intentions: Retrospective-Memory-based Trajectory Prediction | Siheng Chen"><meta property="og:description" content="**[ CVPR 2022 ]** <br>MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data."><meta property="og:image" content="https://Siheng-Chen.github.io/project/memonet/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-04-18T19:34:19+08:00"><meta property="article:modified_time" content="2022-04-18T19:34:19+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://Siheng-Chen.github.io/project/memonet/"},"headline":"Remember Intentions: Retrospective-Memory-based Trajectory Prediction","image":["https://Siheng-Chen.github.io/project/memonet/featured.jpg"],"datePublished":"2022-04-18T19:34:19+08:00","dateModified":"2022-04-18T19:34:19+08:00","author":{"@type":"Person","name":"Chenxin Xu"},"publisher":{"@type":"Organization","name":"Siheng Chen","logo":{"@type":"ImageObject","url":"https://Siheng-Chen.github.io/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_192x192_fill_lanczos_center_3.png"}},"description":"**[ CVPR 2022 ]** \u003cbr\u003eMemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data."}</script><title>Remember Intentions: Retrospective-Memory-based Trajectory Prediction | Siheng Chen</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=c5b982c3e2bbed46e1587db167feca3c><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Siheng Chen</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Siheng Chen</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class="nav-link active" href=/project><span>Projects</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Datasets</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://siheng-chen.github.io/dataset/coperception-uav/><span>CoPerception-UAV</span></a>
<a class=dropdown-item href=https://siheng-chen.github.io/dataset/AM3D/><span>AM3D</span></a>
<a class=dropdown-item href=https://siheng-chen.github.io/dataset/dair-v2x-c-complemented/><span>DAIR-V2X-C-Complemented</span></a></div></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class="article article-project"><div class="article-container pt-3"><h1>Remember Intentions: Retrospective-Memory-based Trajectory Prediction</h1><div class=article-metadata><div><span>Chenxin Xu</span>, <span>Weibo Mao</span>, <span>Wenjun Zhang</span>, <span>Siheng Chen</span></div><span class=article-date>Apr 18, 2022</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/cvpr-2022/>CVPR 2022</a></span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2203.11474 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/MediaBrain-SJTU/MemoNet target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header" href=https://zhuanlan.zhihu.com/p/492362530 target=_blank rel=noopener><i class="fab fa-zhihu mr-1"></i>Zhihu</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:219px><div style=position:relative><img src=/project/memonet/featured_hud1a6dbd11ce411a92c7667f9199b7544_430662_720x2500_fit_q75_h2_lanczos.webp width=720 height=219 alt class=featured-image></div></div><div class=article-container><div class=article-style><h2 id=abstract>Abstract</h2><p>To realize trajectory prediction, most previous methods adopt the parameter-based approach, which encodes all the seen past-future instance pairs into model parameters. However, in this way, the model parameters come from all seen instances, which means a huge amount of irrelevant seen instances might also involve in predicting the current situation, disturbing the performance. To provide a more explicit link between the current situation and the seen instances, <strong>we imitate the mechanism of retrospective memory in neuropsychology and propose MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data</strong>. In MemoNet, we design a pair of memory banks to explicitly store representative instances in the training set, acting as prefrontal cortex in the neural system, and a trainable memory addresser to adaptively search a current situation with similar instances in the memory bank, acting like basal ganglia. During prediction, MemoNet recalls previous memory by using the memory addresser to index related instances in the memory bank. We further propose a two-step trajectory prediction system, where the first step is to leverage MemoNet to predict the destination and the second step is to fulfill the whole trajectory according to the predicted destinations. Experiments show that the proposed MemoNet improves the FDE by <strong>20.3%/10.2%/28.3%</strong> from the previous best method on SDD/ETH-UCY/NBA datasets. Experiments also show that our MemoNet has the ability to trace back to specific instances during prediction, promoting more interpretability.</p><h2 id=result>Result</h2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./images/MemoNet_predictions.png alt loading=lazy data-zoomable></div></div></figure>Diverse intention prediction by MemoNet on SDD, where 20 final intentions are clustered from 120 coarse intention anchors. MemoNet can provide diverse and accurate intention predictions.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./images/MemoNet_result_interpretability.png alt loading=lazy data-zoomable></div></div></figure>Prediction cases with corresponding past-future trajectories traced by memory addresser. MemoNet promotes a more explicit link between the current situation and seen instances.</p><h2 id=citation>Citation</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>@InProceedings{MemoNet_2022_CVPR,
</span></span><span class=line><span class=cl>   author = {Xu, Chenxin and Mao, Weibo and Zhang, Wenjun and Chen, Siheng},
</span></span><span class=line><span class=cl>   title = {Remember Intentions: Retrospective-Memory-based Trajectory Prediction},
</span></span><span class=line><span class=cl>   booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
</span></span><span class=line><span class=cl>   year = {2022}
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><h2 id=acknowledgement>Acknowledgement</h2><p>This research is partially supported by the National Key R&D Program of China under Grant 2021ZD0112801, National Natural Science Foundation of China under Grant 62171276, the Science and Technology Commission of Shanghai Municipal under Grant 21511100900 and CCF-DiDi GAIA Research Collaboration Plan 202112.</p></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F&text=Remember+Intentions%3A+Retrospective-Memory-based+Trajectory+Prediction" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F&t=Remember+Intentions%3A+Retrospective-Memory-based+Trajectory+Prediction" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Remember%20Intentions%3A%20Retrospective-Memory-based%20Trajectory%20Prediction&body=https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F&title=Remember+Intentions%3A+Retrospective-Memory-based+Trajectory+Prediction" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Remember+Intentions%3A+Retrospective-Memory-based+Trajectory+Prediction%20https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2FSiheng-Chen.github.io%2Fproject%2Fmemonet%2F&title=Remember+Intentions%3A+Retrospective-Memory-based+Trajectory+Prediction" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="project-related-pages content-widget-hr"></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by><p class="powered-by copyright-license-text">© 2022 Siheng-Chen</p></p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>