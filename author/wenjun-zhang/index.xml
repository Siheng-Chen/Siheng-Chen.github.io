<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Wenjun Zhang | Siheng Chen</title><link>https://Siheng-Chen.github.io/author/wenjun-zhang/</link><atom:link href="https://Siheng-Chen.github.io/author/wenjun-zhang/index.xml" rel="self" type="application/rss+xml"/><description>Wenjun Zhang</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 18 Apr 2022 19:34:19 +0800</lastBuildDate><image><url>https://Siheng-Chen.github.io/author/wenjun-zhang/avatar_hu19198ffa6d3857220b6c41e765519799_7619_270x270_fill_q75_lanczos_center.jpg</url><title>Wenjun Zhang</title><link>https://Siheng-Chen.github.io/author/wenjun-zhang/</link></image><item><title>Remember Intentions: Retrospective-Memory-based Trajectory Prediction</title><link>https://Siheng-Chen.github.io/project/memonet/</link><pubDate>Mon, 18 Apr 2022 19:34:19 +0800</pubDate><guid>https://Siheng-Chen.github.io/project/memonet/</guid><description>&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>To realize trajectory prediction, most previous methods adopt the parameter-based approach, which encodes all the seen past-future instance pairs into model parameters. However, in this way, the model parameters come from all seen instances, which means a huge amount of irrelevant seen instances might also involve in predicting the current situation, disturbing the performance. To provide a more explicit link between the current situation and the seen instances, &lt;strong>we imitate the mechanism of retrospective memory in neuropsychology and propose MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data&lt;/strong>. In MemoNet, we design a pair of memory banks to explicitly store representative instances in the training set, acting as prefrontal cortex in the neural system, and a trainable memory addresser to adaptively search a current situation with similar instances in the memory bank, acting like basal ganglia. During prediction, MemoNet recalls previous memory by using the memory addresser to index related instances in the memory bank. We further propose a two-step trajectory prediction system, where the first step is to leverage MemoNet to predict the destination and the second step is to fulfill the whole trajectory according to the predicted destinations. Experiments show that the proposed MemoNet improves the FDE by &lt;strong>20.3%/10.2%/28.3%&lt;/strong> from the previous best method on SDD/ETH-UCY/NBA datasets. Experiments also show that our MemoNet has the ability to trace back to specific instances during prediction, promoting more interpretability.&lt;/p>
&lt;h2 id="result">Result&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./images/MemoNet_predictions.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Diverse intention prediction by MemoNet on SDD, where 20 final intentions are clustered from 120 coarse intention anchors. MemoNet can provide diverse and accurate intention predictions.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./images/MemoNet_result_interpretability.png" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Prediction cases with corresponding past-future trajectories traced by memory addresser. MemoNet promotes a more explicit link between the current situation and seen instances.&lt;/p>
&lt;h2 id="citation">Citation&lt;/h2>
&lt;pre tabindex="0">&lt;code>@InProceedings{MemoNet_2022_CVPR,
author = {Xu, Chenxin and Mao, Weibo and Zhang, Wenjun and Chen, Siheng},
title = {Remember Intentions: Retrospective-Memory-based Trajectory Prediction},
booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2022}
}
&lt;/code>&lt;/pre>&lt;h2 id="acknowledgement">Acknowledgement&lt;/h2>
&lt;p>This research is partially supported by the National Key R&amp;amp;D Program of China under Grant 2021ZD0112801, National Natural Science Foundation of China under Grant 62171276, the Science and Technology Commission of Shanghai Municipal under Grant 21511100900 and CCF-DiDi GAIA Research Collaboration Plan 202112.&lt;/p></description></item></channel></rss>