<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: October 19, 2022 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.7c9112d62aa504adadca15bbc66e8e51.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Siheng Chen"><meta name=description content="Siheng Chen"><link rel=alternate hreflang=en-us href=https://Siheng-Chen.github.io/><link rel=canonical href=https://Siheng-Chen.github.io/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://Siheng-Chen.github.io/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Siheng Chen"><meta property="og:url" content="https://Siheng-Chen.github.io/"><meta property="og:title" content="Siheng Chen"><meta property="og:description" content="Siheng Chen"><meta property="og:image" content="https://Siheng-Chen.github.io/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-12-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://Siheng-Chen.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://Siheng-Chen.github.io/"}</script><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Siheng Chen"><title>Siheng Chen</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Siheng Chen</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Siheng Chen</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Datasets</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://siheng-chen.github.io/dataset/coperception-uav/ data-target=https://siheng-chen.github.io/dataset/coperception-uav/><span>CoPerception-UAV</span></a>
<a class=dropdown-item href=https://siheng-chen.github.io/dataset/AM3D/ data-target=https://siheng-chen.github.io/dataset/AM3D/><span>AM3D</span></a>
<a class=dropdown-item href=https://siheng-chen.github.io/dataset/dair-v2x-c-complemented/ data-target=https://siheng-chen.github.io/dataset/dair-v2x-c-complemented/><span>DAIR-V2X-C-Complemented</span></a></div></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/authors/admin/avatar_huf813d250365c7dfc6749e3158f882118_8352_270x270_fill_q75_lanczos_center.jpg alt="Siheng Chen"><div class=portrait-title><h2>Siheng Chen</h2><h3>Associate Professor</h3><h3><a href=https://sjtu.edu.cn/ target=_blank rel=noopener><span>Shanghai Jiao Tong University</span></a></h3><h3><a href=https://cmic.sjtu.edu.cn/EN/Default.aspx target=_blank rel=noopener><span>Cooperative Medianet Innovation Center (CMIC)</span></a></h3><h3><a href=https://www.shlab.org.cn/ target=_blank rel=noopener><span>Shanghai Artificial Intelligence Laboratory</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=mailto:sihengc@sjtu.edu.cn aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/siheng-chen-705b2832/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=W_Q33RMAAAAJ&hl=zh-CN" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://github.com/siheng-chen target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://www.zhihu.com/people/sjtu-magic target=_blank rel=noopener aria-label=zhihu><i class="fab fa-zhihu big-icon"></i></a></li><li><a href=/uploads/cv.pdf aria-label=cv><i class="ai ai-cv big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>Biography</h1><div class=article-style><p>Siheng Chen 陈思衡 is a tenure-track associate professor of <a href=https://sjtu.edu.cn target=_blank rel=noopener>Shanghai Jiao Tong University</a> and co-PI at <a href=https://www.shlab.org.cn/ target=_blank rel=noopener>Shanghai AI laboratory</a>. He received his doctorate from Carnegie Mellon University. His research interests include graph machine learning and collective intelligence. Dr. Chen&rsquo;s work on sampling theory of graph data received the 2018 IEEE Signal Processing Society Young Author Best Paper Award. His co-authored paper on structural health monitoring received ASME SHM/NDE 2020 Best Journal Paper Runner-Up Award and another paper on 3D point cloud processing received the Best Student Paper Award at 2018 IEEE Global Conference on Signal and Information Processing. His technique on joint perception and prediction was applied on all the UBER&rsquo;s autonomous cars. Dr. Chen also contributed to the project of scene-aware interaction, winning MERL President&rsquo;s Award. He also serves as the associate editor of IEEE Transactions on Signal and Information Processing over Networks.</p><!-- 
  <i class="fas fa-download  pr-1 fa-fw"></i> Download my 

<a href="/cv.pdf" target="_blank">Curriculum vitae</a>
. --><h3 id=join-us>Join us:</h3><p>We are actively hiring! I am looking for motivated students (PostDoc and interns) to join my group. For prospective students, if you are passionate about multi-agent learning, graph machine learning and autonomous driving, and interested in working with us, feel free to drop me an email!</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Graph machine learning</li><li>Multi-agent learning</li><li>Collaborative perception</li><li>Federated learning</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>Ph.D in Electrical and Computer Engineering</p><p class=institution>Carnegie Mellon University</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>Master of Science in Machine Learning</p><p class=institution>Carnegie Mellon University</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>Bachelor of Science in Electronic Engineering</p><p class=institution>Beijing Institute of Technology</p></div></li></ul></div></div></div></div></div></section><section id=recent_news class="home-section wg-markdown"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent News</h1><p class=mt-1><a href=/news>All news&#187;</a></p></div><div class="col-12 col-lg-8"><p><strong>[Oct. 2022]</strong> One paper is accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence</p><p><strong>[Oct. 2022]</strong> <a href=https://github.com/MediaBrain-SJTU/where2comm target=_blank rel=noopener>Where2comm</a> is reported by <a href=https://www.jiqizhixin.com/articles/2022-10-11-28 target=_blank rel=noopener>机器之心</a></p><p><strong>[Sep. 2022]</strong> One paper is accepted to NeurIP 2022</p><p><strong>[Aug. 2022]</strong> One paper is accepted to Physics of Fluids</p><p><strong>[July 2022]</strong> Three papers are accepted to ECCV 2022</p><p><strong>[July 2022]</strong> One paper is accepted to Nature Computational Science</p><p><strong>[June 2022]</strong> One paper is accepted to IEEE Robotics and Automation Letters</p><p><strong>[Mar. 2022]</strong> Three papers are accepted to CVPR 2022</p><p><strong>[Mar. 2022]</strong> Two papers are accepted to ICASSP 2022</p><p><strong>[Jan. 2022]</strong> One paper is accepted to IEEE Transactions on Wireless Communications</p></div></div></div></section><section id=publications class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent Publications</h1></div><div class="col-12 col-lg-8"><div class="alert alert-note"><div>Quickly discover relevant content by <a href=./publication/>filtering publications</a>.</div></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Yue Hu</span>, <span>Shaoheng Fang</span>, <span>Zixing Lei</span>, <span>Yiqi Zhong</span>, <span>Siheng Chen</span></span>
(2022).
<a href=/publication/hu-where-2-comm-2022/>Where2comm: Communication-efficient collaborative perception via spatial confidence maps</a>.
<em>Neural Information Processing Systems (NeurIPS)</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/hu-where-2-comm-2022/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Yiqi Zhong</span>, <span>Zhenyang Ni</span>, <span>Siheng Chen</span>, <span>Ulrich Neumann</span></span>
(2022).
<a href=/publication/zhong-aware-2022/>Aware of the history: Trajectory forecasting with the local behavior data</a>.
<em>European Conference on Computer Vision (ECCV)</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/zhong-aware-2022/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Zixing Lei</span>, <span>Shunli Ren</span>, <span>Yue Hu</span>, <span>Wenjun Zhang</span>, <span>Siheng Chen</span></span>
(2022).
<a href=/publication/lei-latency-aware-2022/>Latency-aware collaborative perception</a>.
<em>European Conference on Computer Vision (ECCV)</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/lei-latency-aware-2022/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Qi Yang</span>, <span>Yujie Zhang</span>, <span>Siheng Chen</span>, <span>Yiling Xu</span>, <span>Jun Sun</span>, <span>Zhan Ma</span></span>
(2022).
<a href=/publication/yang-mped-2022/>MPED: Quantifying point cloud distortion based on multiscale potential energy discrepancy</a>.
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/yang-mped-2022/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Maosen Li</span>, <span>Siheng Chen</span>, <span>Zijing Zhang</span>, <span>Lingxi Xie</span>, <span>Qi Tian</span>, <span>Ya Zhang</span></span>
(2022).
<a href=/publication/li-skeleton-parted-2022/>Skeleton-parted graph scattering networks for 3D human motion prediction</a>.
<em>European Conference on Computer Vision (ECCV)</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/li-skeleton-parted-2022/cite.bib>Cite</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Jiang-Zhou Peng</span>, <span>Yi-Zhe Wang</span>, <span>Siheng Chen</span>, <span>Zhi-Hua Chen</span>, <span>Wei-Tao Wu</span>, <span>Nadine Aubry</span></span>
(2022).
<a href=/publication/peng-grid-2022/>Grid adaptive reduced-order model of fluid flow based on graph convolutional neural network</a>.
<em>Physics of Fluids</em>.<p><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/peng-grid-2022/cite.bib>Cite</a></p></div><div class=see-all><a href=/publication/>See all publications
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=projects class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Projects</h1></div><div class="col-12 col-lg-8"><span class="d-none default-project-filter">*</span><div class=project-toolbar><div class=project-filters><div class=btn-toolbar><div class="btn-group flex-wrap"><a href=# data-filter=* class="btn btn-primary btn-lg active">All</a>
<a href=# data-filter=.js-id-deep-learning class="btn btn-primary btn-lg">Deep Learning</a>
<a href=# data-filter=.js-id-demo class="btn btn-primary btn-lg">Other</a></div></div></div></div><div class="isotope projects-container row js-layout-row"><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/groupnet/>GroupNet: Multiscale Hypergraph Neural Networks for Trajectory Prediction with Relational Reasoning</a></div><a href=/project/groupnet/ class=summary-link><div class=article-style><strong>[ CVPR 2022 ]</strong><br>GroupNet, a multiscale hypergraph neural network, which is novel in terms of both interaction capturing and representation learning.</div></a><div class="stream-meta article-metadata"><div><span>Chenxin Xu</span>, <span>Maosen Li</span>, <span>Zhenyang Ni</span>, <span>Ya Zhang</span>, <span>Siheng Chen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2204.08770 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/MediaBrain-SJTU/GroupNet target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.techbeat.net/talk-info?id=686" target=_blank rel=noopener>Talk</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://zhuanlan.zhihu.com/p/510918682 target=_blank rel=noopener><i class="fab fa-zhihu mr-1"></i>Zhihu</a></div></div><div class=ml-3><a href=/project/groupnet/><img src=/project/groupnet/featured_hu3c049b915c211dea12e7ac161e36a7a8_670709_150x0_resize_q75_h2_lanczos.webp height=58 width=150 alt="GroupNet: Multiscale Hypergraph Neural Networks for Trajectory Prediction with Relational Reasoning" loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/memonet/>Remember Intentions: Retrospective-Memory-based Trajectory Prediction</a></div><a href=/project/memonet/ class=summary-link><div class=article-style><strong>[ CVPR 2022 ]</strong><br>MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data.</div></a><div class="stream-meta article-metadata"><div><span>Chenxin Xu</span>, <span>Weibo Mao</span>, <span>Wenjun Zhang</span>, <span>Siheng Chen</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2203.11474 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/MediaBrain-SJTU/MemoNet target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://zhuanlan.zhihu.com/p/492362530 target=_blank rel=noopener><i class="fab fa-zhihu mr-1"></i>Zhihu</a></div></div><div class=ml-3><a href=/project/memonet/><img src=/project/memonet/featured_hud1a6dbd11ce411a92c7667f9199b7544_430662_150x0_resize_q75_h2_lanczos.webp height=46 width=150 alt="Remember Intentions: Retrospective-Memory-based Trajectory Prediction" loading=lazy></a></div></div></div></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><div class="col-12 col-lg-8"><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:sihengc@sjtu.edu.cn>sihengc@sjtu.edu.cn</a></span></li><li><i class="fa-li fas fa-map-marker fa-2x" aria-hidden=true></i>
<span id=person-address>800 Dongchuan Road, Shanghai, 200240</span></li><li><i class="fa-li fas fa-compass fa-2x" aria-hidden=true></i>
<span>Enter SEIEE Building 5 and take the stairs to Office 303A on Floor 3</span></li></ul></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by><p class="powered-by copyright-license-text">© 2022 Siheng-Chen</p></p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>