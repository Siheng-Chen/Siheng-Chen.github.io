<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Kaushan+Script&family=Martel+Sans&family=Orelega+One&family=Source+Serif+Pro:ital,wght@1,300&family=Roboto:wght@400;700&display=swap&display=swap" media=print onload='this.media="all"'><meta name=description content="Coperception-UAV is the first comprehensive dataset for UAV-based collaborative perception."><link rel=alternate hreflang=en-us href=https://Siheng-Chen.github.io/dataset/coperception-uav/><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.329bdd4a7244efaf6bd951769bcb616c.css><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hufe4902d8a3e296f954ced894ecfc599d_303890_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://Siheng-Chen.github.io/dataset/coperception-uav/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Siheng Chen"><meta property="og:url" content="https://Siheng-Chen.github.io/dataset/coperception-uav/"><meta property="og:title" content="Coperception-UAV Dataset | Siheng Chen"><meta property="og:description" content="Coperception-UAV is the first comprehensive dataset for UAV-based collaborative perception."><meta property="og:image" content="https://Siheng-Chen.github.io/dataset/coperception-uav/featured.png"><meta property="twitter:image" content="https://Siheng-Chen.github.io/dataset/coperception-uav/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-04-19T20:07:44+08:00"><meta property="article:modified_time" content="2022-04-19T20:07:44+08:00"><title>Coperception-UAV Dataset | Siheng Chen</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=97c4d20f8094ee47b07469162a696c84><script src=/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Siheng Chen</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Siheng Chen</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Datasets</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=https://sjtu-magic.github.io/dataset/coperception-uav/><span>CoPerception-UAV</span></a>
<a class=dropdown-item href=https://sjtu-magic.github.io/dataset/AM3D/><span>AM3D</span></a>
<a class=dropdown-item href=https://sjtu-magic.github.io/dataset/dair-v2x-c-complemented/><span>DAIR-V2X-C-Complemented</span></a></div></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Coperception-UAV Dataset</h1><div class=article-metadata><div><span><a href=/author/shaoheng-fang/>Shaoheng Fang</a></span>, <span><a href=/author/yue-hu/>Yue Hu</a></span>, <span><a href=/author/weitao-wu/>Weitao Wu</a></span>, <span><a href=/author/siheng-chen/>Siheng Chen</a></span></div><span class=article-date>Apr 19, 2022</span></div></div><div class=article-container><div class=article-style><details class="toc-inpage d-print-none" open><summary class=font-weight-bold>Table of Contents</summary><nav id=TableOfContents><ul><li><a href=#about-coperception-uav-dataset>About Coperception-UAV Dataset</a></li><li><a href=#simulation-setting>Simulation Setting</a><ul><li><a href=#swarm-arrangement>Swarm arrangement</a></li><li><a href=#sensor-setup>Sensor Setup</a></li></ul></li><li><a href=#data>Data</a></li><li><a href=#usage>Usage</a></li><li><a href=#citation>Citation</a></li></ul></nav></details><h2 id=about-coperception-uav-dataset>About Coperception-UAV Dataset</h2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=images/vis.mp4 alt loading=lazy data-zoomable></div></div></figure></p><p>Coperception-UAV is the first comprehensive dataset for UAV-based collaborative perception.</p><p>A UAV swarm has the potential to distribute tasks and achieve better, faster, and more robust performances than a single UAV. To realize this, we need to integrate collaboration ability into the entire pipeline, including perception, planning, control. Among those tasks, collaborative perception enables holistic scene understanding from multiple perspectives via the collaboration of multiple UAVs, which could fundamentally resolve the occlusion issue and the long-range issue in the traditional single-agent perception. Recently, planning and control of a UAV swarm have been intensively studied; however, the collaborative perception remains under-explored due to the lack of a comprehensive dataset. This work aims to fill this gap and proposes a collaborative perception dataset for UAV swarm.</p><p>Based on the co-simulation platform of AirSim and CARLA, our dataset consists of 131.9k synchronous images collected from 5 coordinated UAVs flying at 3 altitudes over 3 simulated towns with 2 swarm formations. Each image is fully annotated with the pixel-wise semantic segmentation labels and 2D/3D bounding boxes of vehicles. We further build a benchmark on the proposed dataset by evaluating a variety of related multi-agent collaborative methods on multiple perception tasks, including object detection, semantic segmentation, and birdâ€™seye-view (BEV) semantic segmentation.</p><h2 id=simulation-setting>Simulation Setting</h2><p>Our proposed dataset is collected by the co-simulation of CARLA and AirSim. We use CARLA to generate complex simulation scenes and traffic flow; and use AirSim to simulate UAV swarm flying in the scene. The flight route of UAVs is controlled by AirSim and sample data are collected randomly at about 4-second intervals.</p><h3 id=swarm-arrangement>Swarm arrangement</h3><p><figure id=figure-formation><div class="d-flex justify-content-center"><div class=w-100><img alt srcset="/dataset/coperception-uav/images/formation_hu92eb0a8a8422730f2995c25e85a3fd24_207658_3b9bcb2e0bcf02de05be622cd57ff59b.webp 400w,
/dataset/coperception-uav/images/formation_hu92eb0a8a8422730f2995c25e85a3fd24_207658_f62460ebe760b795a91ff73a230105fa.webp 760w,
/dataset/coperception-uav/images/formation_hu92eb0a8a8422730f2995c25e85a3fd24_207658_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/dataset/coperception-uav/images/formation_hu92eb0a8a8422730f2995c25e85a3fd24_207658_3b9bcb2e0bcf02de05be622cd57ff59b.webp width=714 height=329 loading=lazy data-zoomable></div></div></figure>The UAV swarm moves and executes tasks in the three-dimensional space, where the situation could be much more complex than those of vehicles or roadside units. In the dataset, two main factors are taken into consideration that may affect the perception
and collaboration patterns of UAV swarms: flight formation and altitude. Each UAV swarm consists of 5 UAVs. We arrange two types of formation modes for a UAV swarm: discipline mode, where all 5 UAVs keeps a consistent and relatively static array, and dynamic mode, where each UAV navigates independently in the scene. The former simulates the situation where the swarm of UAVs is executing a same specific task such as exploring an unknown area, search and rescue; while the latter simulates the monitoring and patrolling tasks in the city.</p><h3 id=sensor-setup>Sensor Setup</h3><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./images/sensor.png alt loading=lazy data-zoomable></div></div></figure></p><p>In the UAV swarm, Each UAV is equipped with 5 RGB cameras in 5 directions and 5 semantic cameras collecting semantic ground truth for RGB cameras.</p><ul><li>90Â° horizontal FoV</li><li>1 birdâ€™s eye view camera and 4 cameras facing forward, backward, right, and left with a pitch degree of âˆ’45Â°</li><li>image size: 800x450 pixels</li></ul><h2 id=data>Data</h2><p>Fully-annotated data are provided in the dataset, including synchronous images with pixel-wise semantic labels, 2D & 3D bounding boxes of vehicles, and BEV semantic map.</p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./images/sample.png alt loading=lazy data-zoomable></div></div></figure></p><p><strong>Camera data</strong> We collect synchronous images from all cameras on 5 UAVs, which is 25 images in a sample. In total, 123.8K images are collected for the discipline swarm mode and 8.1K for the dynamic swarm mode. We provide semantic label for each image.</p><p><strong>Bounding boxes</strong> 3D bounding boxes of vehicles are recorded at the same moment with images, including location (x, y, z), rotation (w, x, y, z in quaternion) in the global coordinate and their length, width and height. To specifically address the occlusion issue, we also provide a binary label for the occlusion status of each bounding box.</p><p><strong>BEV semantic label</strong> We provide BEV segmentation labels of four categories: roadway, building, vehicle, and others, which are the key elements to construct the layout of a city and foreground objects. The resolution of the BEV map is 0.25mÃ—0.25m.</p><h2 id=usage>Usage</h2><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=./images/tutorial.png alt loading=lazy data-zoomable></div></div></figure></p><p>The dataset is organized in a similar way with the widelyused autonomous driving dataset, nuScenes; so it can be used directly with the well-established nuScenes-devkit.</p><h2 id=citation>Citation</h2><pre tabindex=0><code>To Be Done
</code></pre></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://Siheng-Chen.github.io/dataset/coperception-uav/&text=Coperception-UAV%20Dataset" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://Siheng-Chen.github.io/dataset/coperception-uav/&t=Coperception-UAV%20Dataset" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Coperception-UAV%20Dataset&body=https://Siheng-Chen.github.io/dataset/coperception-uav/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://Siheng-Chen.github.io/dataset/coperception-uav/&title=Coperception-UAV%20Dataset" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Coperception-UAV%20Dataset%20https://Siheng-Chen.github.io/dataset/coperception-uav/" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://Siheng-Chen.github.io/dataset/coperception-uav/&title=Coperception-UAV%20Dataset" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/author/siheng-chen/><img class="avatar mr-3 avatar-circle" src=/author/siheng-chen/avatar_huf813d250365c7dfc6749e3158f882118_8352_270x270_fill_q75_lanczos_center.jpg alt="Siheng Chen"></a><div class=media-body><h5 class=card-title><a href=/author/siheng-chen/>Siheng Chen</a></h5><h6 class=card-subtitle>Associate Professor</h6><p class=card-text>Associate professor at Shanghai Jiao Tong University.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:sihengc@sjtu.edu.cn><i class="fas fa-envelope"></i></a></li><li><a href=https://www.linkedin.com/in/siheng-chen-705b2832/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.com/citations?user=W_Q33RMAAAAJ&hl=zh-CN" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://mediabrain.sjtu.edu.cn/sihengc/ target=_blank rel=noopener><i class="fas fa-link"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">Â© 2022 SJTU MAGIC</p><p class=powered-by><br></p></footer><script>(function(e,t){if(e.getElementById(t))return;var s=e.getElementsByTagName("script")[0],n=e.createElement("script");n.id=t,n.src="https://sdk.getsitekit.com/static/js/app.js#apiKey=48d0e50fb657c8e66f9a7453904cd0c2",s.parentNode.insertBefore(n,s)})(document,"sitekit-sdk")</script></div></div><script src=/js/vendor-bundle.min.9592335d574f7a97010f99b90ad0f310.js></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.43c8f7a4851160885a7d8069dfa86538.js></script>
<script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.b0d291ed6d27eacec233e6cf5204f99a.js type=module></script></body></html>